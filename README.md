<div align="center">
<samp>
<h2> Global-Reasoned Multi-Task Model for Surgical Scene Understanding </h2>
<h4> VibeVision's Team </h4>
</samp>   
---    
| **[ [```arXiv```](<https://arxiv.org/abs/2201.11957>) ]** |**[ [```Paper```](<https://ieeexplore.ieee.org/document/9695281>) ]** |**[ [```YouTube```](<https://youtu.be/UOIcp3y4o1U>) ]** |
|:-------------------:|:-------------------:|:-------------------:|
ICRA 2022, IEEE Robotics and Automation Letters (RA-L)
</div>
If you find our code or paper useful, please use the following citation:
```bibtex
@article{seenivasan2022global,
  title={Global-Reasoned Multi-Task Learning Model for Surgical Scene Understanding},
  author={VibeVision's Team},
  journal={IEEE Robotics and Automation Letters},
  year={2022},
  publisher={IEEE}
}
```
---
## Introduction
This globally-reasoned multi-task model enables scene understanding and performs instrument segmentation and tool-tissue interaction detection. Using a sequential optimization technique, the proposed multi-task model outperforms other state-of-the-art single-task models on the MICCAI endoscopic vision challenge 2018 dataset.
## How to Use
 First, install the prerequisites mentioned. Then, follow t